{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fulfil Business Requirement 2: Accurately predict if a cherry leaf is healthy or contains powdery mildew\n",
        "* Answer hypothesis #1: Mildew infected leaves will have clear signs of white mildew that can differentiate them from a healthy leaf.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/raw/cherry-leaves/train\n",
        "* inputs/datasets/raw/cherry-leaves/validation\n",
        "* inputs/datasets/raw/cherry-leaves/test\n",
        "* image shape .pkl files\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Image augmentation of training dataset\n",
        "* CNN (Convolutional Neural Network) model tuning using kears-tuner\n",
        "* Tuned CNN model creation and training.\n",
        "* Trained model saved and exported to outputs folder\n",
        "* Learning curve plots for model performance.\n",
        "* Model evaluation with confusion matrix plot\n",
        "* Test prediction on random single image file.\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "* \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras_tuner as kt\n",
        "import joblib\n",
        "import shutil\n",
        "import random\n",
        "from matplotlib.image import imread\n",
        "from IPython.display import Image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the working directory from its current folder to its parent folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/cherry-mildew-detector/jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make the parent of the current directory the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/cherry-mildew-detector'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set input directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "set paths to specific data folders required in notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the raw data directory is inputs/datasets/raw/cherry-leaves\n",
            "the training data directory is inputs/datasets/raw/cherry-leaves/train\n",
            "the validation data directory is inputs/datasets/raw/cherry-leaves/validation\n",
            "the test data directory is inputs/datasets/raw/cherry-leaves/test\n"
          ]
        }
      ],
      "source": [
        "raw_data_dir = 'inputs/datasets/raw/cherry-leaves'\n",
        "train_data_dir = 'inputs/datasets/raw/cherry-leaves/train'\n",
        "val_data_dir = 'inputs/datasets/raw/cherry-leaves/validation'\n",
        "test_data_dir = 'inputs/datasets/raw/cherry-leaves/test'\n",
        "\n",
        "print('the raw data directory is', raw_data_dir)\n",
        "print('the training data directory is', train_data_dir)\n",
        "print('the validation data directory is', val_data_dir)\n",
        "print('the test data directory is', test_data_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This version is already available - create a new version if required.\n"
          ]
        }
      ],
      "source": [
        "version = 'v1' # change version number for each iteration\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print('This version is already available - create a new version if required.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels for images are ['healthy', 'powdery_mildew']\n"
          ]
        }
      ],
      "source": [
        "labels = os.listdir(test_data_dir)\n",
        "print('Labels for images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_128 = 'outputs/v1/image_shape_half.pkl'\n",
        "image_50 = 'outputs/v1/image_shape_small.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "### Augment training image data and rescale validation and test image data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define image size and batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Allows size adjustment for tuning\n",
        "IMG_SIZE = (128, 128) #image_128[:2] #can also be defined with any size eg.(128, 128)  \n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define data augmentation for training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values\n",
        "    rotation_range=30,  # Random rotation up to 30 degrees\n",
        "    width_shift_range=0.2,  # Shift width by 20%\n",
        "    height_shift_range=0.2,  # Shift height by 20%\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Zoom into image\n",
        "    horizontal_flip=True,  # Flip horizontally\n",
        "    fill_mode='nearest'  # Fill empty space after transformations\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define rescaling for vallidation and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2944 images belonging to 2 classes.\n",
            "Found 420 images belonging to 2 classes.\n",
            "Found 844 images belonging to 2 classes.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'healthy': 0, 'powdery_mildew': 1}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'  # One-hot encoding for softmax\n",
        ")\n",
        "\n",
        "val_set = val_test_datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_set = val_test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "### Define base CNN model architecture and tune hyperparameters to optimise model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_shape = (128, 128, 3)  # Modify as needed or use .pkl file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define model for tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input image shape\n",
        "    model.add(Input(shape=image_shape))\n",
        "\n",
        "    # First Conv2D layer with tunable filter size\n",
        "    model.add(Conv2D(\n",
        "        filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=32), \n",
        "        kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Second Conv2D layer\n",
        "    model.add(Conv2D(\n",
        "        filters=hp.Int('conv2_filters', min_value=64, max_value=256, step=64), \n",
        "        kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Dense layer with tunable units\n",
        "    model.add(Dense(hp.Int('dense_units', min_value=64, max_value=256, step=64), activation='relu'))\n",
        "\n",
        "    # Dropout layer with tunable rate\n",
        "    model.add(Dropout(hp.Float('dropout', min_value=0.3, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer (2 neurons, Softmax activation)\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile with tunable learning rate\n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialise the tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from outputs/v1/cherry_mildew_tuning/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory= file_path,\n",
        "    project_name='cherry_mildew_tuning'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "set early stop if not improving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner.search(train_set, validation_data=val_set, epochs=20, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Export the best 10 hyperparameter results as a table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Trial  Conv1 Filters  Conv2 Filters  Dense Units  Dropout Rate  \\\n",
            "0      1             32            128          128           0.4   \n",
            "1      2             64            256          128           0.5   \n",
            "2      3            128            256          192           0.4   \n",
            "3      4             96            192           64           0.3   \n",
            "4      5             32            256          256           0.3   \n",
            "5      6             96            256          256           0.3   \n",
            "6      7             96            192           64           0.3   \n",
            "7      8             32             64          128           0.4   \n",
            "8      9             96            256          256           0.3   \n",
            "9     10             96             64          128           0.3   \n",
            "\n",
            "   Learning Rate  \n",
            "0          0.001  \n",
            "1          0.001  \n",
            "2          0.001  \n",
            "3          0.001  \n",
            "4          0.001  \n",
            "5          0.001  \n",
            "6          0.001  \n",
            "7          0.001  \n",
            "8          0.001  \n",
            "9          0.001  \n",
            "Results saved to: outputs/v1/hyperparameter_tuning_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Get the top 10 hyperparameter sets\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=10)\n",
        "\n",
        "# Extract hyperparameters into a DataFrame\n",
        "hp_data = []\n",
        "for i, hp in enumerate(best_hps):\n",
        "    hp_data.append({\n",
        "        'Trial': i + 1,\n",
        "        'Conv1 Filters': hp.get('conv1_filters'),\n",
        "        'Conv2 Filters': hp.get('conv2_filters'),\n",
        "        'Dense Units': hp.get('dense_units'),\n",
        "        'Dropout Rate': hp.get('dropout'),\n",
        "        'Learning Rate': hp.get('learning_rate'),\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(hp_data)\n",
        "\n",
        "# Save as CSV in the output directory\n",
        "csv_path = os.path.join(file_path, \"hyperparameter_tuning_results.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Display table\n",
        "print(df)\n",
        "\n",
        "print(f\"Results saved to: {csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the best model from hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0] # best hyperparameters\n",
        "best_model = tuner.hypermodel.build(best_hp) # build model from best hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115200</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,745,728</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m36,992\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115200\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m14,745,728\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,783,874</span> (56.40 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,783,874\u001b[0m (56.40 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,783,874</span> (56.40 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,783,874\u001b[0m (56.40 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **NB: tuning results removed at this point as files too large and causing issues for workspace**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model training\n",
        "\n",
        "### Uses best CNN model architecture from top hyperparameter tuning result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_shape = (128, 128, 3)  # Modify as needed or use .pkl file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input image shape\n",
        "    model.add(Input(shape=image_shape))\n",
        "\n",
        "    # First Conv2D layer with 32 filters\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Second Conv2D layer with 128 filters\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Dense layer with 128 dense units\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    # Dropout layer with dropout rate of 0.4\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Output layer (2 neurons, Softmax activation)\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Adam optimiser has default 0.001 learning rate\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set early stop if not improving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit model for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          validation_data=val_set,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/mildew_detector_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusions: \n",
        "* \n",
        "\n",
        "\n",
        "Next steps:\n",
        "* "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
